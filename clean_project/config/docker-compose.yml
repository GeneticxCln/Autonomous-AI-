version: "3.9"

services:
  # Main API Service
  api:
    build: .
    container_name: agent_api
    environment:
      - ENVIRONMENT=production
      - API_DEBUG=false
      - DATABASE_URL=sqlite:///./agent_enterprise.db
      - REDIS_URL=redis://redis:6379/0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - DISTRIBUTED_ENABLED=true
      - ENABLE_TRACING=true
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=14268
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-dev-secret-please-change}
    ports:
      - "8000:8000"
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs

  # Redis Cache and Message Queue
  redis:
    image: redis:7-alpine
    container_name: agent_redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Asynchronous Worker Pool
  worker:
    build: .
    container_name: agent_worker
    command: python -m agent_system.worker --queue agent.jobs
    environment:
      - ENVIRONMENT=production
      - REDIS_URL=redis://redis:6379/0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - DISTRIBUTED_ENABLED=true
      - LOG_LEVEL=INFO
      - PYTHONPATH=/app
    depends_on:
      - redis
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs

  # Nginx Load Balancer
  nginx:
    image: nginx:1.25-alpine
    container_name: agent_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/sites:/etc/nginx/sites-available:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - api
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: agent_prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Alertmanager Notifications
  alertmanager:
    image: prom/alertmanager:latest
    container_name: agent_alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    depends_on:
      - prometheus
      - api
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: agent_grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
      - alertmanager
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Jaeger Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: agent_jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
      - "6831:6831/udp"  # UDP collector
      - "6832:6832/udp"  # UDP collector
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Database Backup Service
  database_backup:
    build: .
    container_name: agent_db_backup
    command: >
      sh -c "
      while true; do
        echo 'Running database backup...'
        cp /app/data/agent_enterprise.db /app/backups/agent_enterprise_$$(date +%Y%m%d_%H%M%S).db
        find /app/backups -name '*.db' -mtime +7 -delete
        echo 'Backup complete. Sleeping for 1 hour...'
        sleep 3600
      done
      "
    environment:
      - ENVIRONMENT=production
      - PYTHONPATH=/app
    volumes:
      - ./data:/app/data
      - ./backups:/app/backups
    depends_on:
      - api
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

volumes:
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local

networks:
  default:
    name: agent_network
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
